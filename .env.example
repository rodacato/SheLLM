# SheLLM Configuration

# Port the HTTP server listens on
PORT=6100

# Max time (ms) to wait for a CLI provider process before killing it
TIMEOUT_MS=120000

# Max CLI provider processes running at the same time (e.g. concurrent claude/gemini calls).
# Requests beyond this limit wait in a queue. This does NOT limit Express — it limits
# child_process spawns to avoid saturating the machine with heavy CLI processes.
MAX_CONCURRENT=2

# Max requests waiting in queue when all concurrent slots are busy.
# Once the queue is full, new requests are rejected with HTTP 429.
MAX_QUEUE_DEPTH=10

# How long (ms) to cache provider health-check results before re-probing
HEALTH_CACHE_TTL_MS=30000

# Log level: debug, info, warn, error (default: info)
# At 'info': health checks are suppressed. At 'debug': everything is logged.
LOG_LEVEL=info

# Model aliases (JSON) — map custom names to existing models/providers
# Enables OpenAI-style model names like "gpt-4" to route to SheLLM providers
# SHELLM_ALIASES='{"gpt-4":"claude","gpt-3.5-turbo":"cerebras","fast":"cerebras-8b","smart":"claude-opus"}'

# Global rate limit (all clients combined, requests per minute)
# SHELLM_GLOBAL_RPM=30

# Admin API password (enables /admin/* endpoints for key management)
# Uses HTTP Basic auth: curl -u admin:<password> http://localhost:6100/admin/keys
# When not set, admin endpoints return 501
# SHELLM_ADMIN_PASSWORD=your-secret-password

# Admin username validation (optional — when set, only this username is accepted)
# When not set, any username is accepted (only the password matters)
# SHELLM_ADMIN_USER=admin

# Max failed admin login attempts per IP before 5-minute lockout (default: 5)
# SHELLM_ADMIN_MAX_ATTEMPTS=5

# Cerebras API (optional — only needed if using cerebras provider)
# CEREBRAS_API_KEY=csk-xxx
